{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Simple tool to analyze data from www.data.gouv.fr\n",
    "\n",
    "**Note:** This is a Jupyter notebook which is also available as its executable export as a Python 3 script (therefore with automatically generated comments)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sys import\n",
    "import sys, os, re\n",
    "# Common imports\n",
    "import math\n",
    "import numpy             as NP\n",
    "import numpy.random      as RAND\n",
    "import scipy.stats       as STATS\n",
    "from scipy import sparse\n",
    "from scipy import linalg\n",
    "\n",
    "# Better formatting functions\n",
    "from IPython.display import display, HTML\n",
    "from IPython import get_ipython\n",
    "\n",
    "import matplotlib        as MPL\n",
    "import matplotlib.pyplot as PLT\n",
    "import seaborn as SNS\n",
    "SNS.set(font_scale=1)\n",
    "\n",
    "# Python programming\n",
    "from itertools import cycle\n",
    "from time import time\n",
    "import datetime\n",
    "\n",
    "# Using pandas\n",
    "import pandas as PAN\n",
    "import xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"For now, reduce python warnings, I will look into this later\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import my own modules\n",
    "The next cell attempts to give user some information if things improperly setup.\n",
    "Intended to work both in Jupyter and when executing the Python file directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not get_ipython() is None and os.path.abspath(\"../source/\") not in sys.path:\n",
    "    sys.path.append(os.path.abspath(\"../source/\"))\n",
    "try:\n",
    "    from lib.utilities     import *\n",
    "    from lib.figureHelpers import *\n",
    "    from lib.DataMgrJSON   import *\n",
    "    from lib.DataMgr       import *\n",
    "    \n",
    "    import lib.basicDataCTE as DCTE\n",
    "except Exception as err:\n",
    "    print(\"Could not find library 'lib' with contents 'DataGouvFr' \")\n",
    "    if get_ipython() is None:\n",
    "        print(\"Check the PYTHONPATH environment variable which should point to 'source' wich contains 'lib'\")\n",
    "    else:\n",
    "        print(\"You are supposed to be running in JupySessions, and '../source/lib' should exist\")\n",
    "    raise err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check environment\n",
    "\n",
    "It is expected that:\n",
    "- your working directory is named `JupySessions`, \n",
    "- that it has subdirectories \n",
    "   - `images/*` where generated images may be stored to avoid overcrowding. \n",
    "- At the same level as your working dir there should be directories \n",
    "   - `../data` for storing input data and \n",
    "   - `../source` for python scripts.\n",
    "   \n",
    "My package library is in `../source/lib`, and users running under Python (not in Jupyter) should\n",
    "set their PYTHONPATH to include \"../source\" ( *or whatever appropriate* )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkSetup(chap=\"Chap01\")\n",
    "ImgMgr = ImageMgr(chapdir=\"Chap01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CSV and XLSX data from remote \n",
    "The `dataFileVMgr` will manage a cache of data files in `../data`, the data will be downloaded\n",
    "from www.data.gouv.fr using a request for datasets with badge '`covid-19`' if a more recent\n",
    "version is present on the remote site. The meta information is stored/cached  in `../data/.data`\n",
    "as the pickle of a json.\n",
    "\n",
    "We check what is in the cache/data directory; for each file, we identify the latest version, \n",
    "and list this below to make sure. The file name will usually contain a time stamp; this has to do with \n",
    "the version management/identification technique used when downloading from www.data.gouv.fr.\n",
    "\n",
    "For the files used in this notebook, the latest version is used/loaded irrespective of the\n",
    "timestamp used in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataFileVMgr = manageAndCacheDataFilesFRDG(\"../data\",  maxDirSz= 80*(2**10)**2)\n",
    "dataFileVMgr.getRemoteInfo()\n",
    "dataFileVMgr.updatePrepare()\n",
    "dataFileVMgr.cacheUpdate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFileVMgr.showMetaData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Most recent versions of files in data directory:\")\n",
    "for f in dataFileVMgr.listMostRecent() :\n",
    "    print(f\"\\t{f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "last = lambda x: dataFileVMgr.getRecentVersion(x,default=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ensures we load the most recent version, so that it is not required to update the list \n",
    "below. The timestamps shown in the following sequence will be update by the call to `getRecentVersion`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dailyDepCsv    = last(\"sursaud-covid19-quotidien-2020-04-11-19h00-departement.csv\")\n",
    "dailyRegionCsv = last(\"sursaud-covid19-quotidien-2020-04-11-19h00-region.csv\")\n",
    "dailyFranceCsv = last(\"sursaud-covid19-quotidien-2020-04-12-19h00-france.csv\")\n",
    "dailyXlsx      = last(\"sursaud-covid19-quotidien-2020-04-12-19h00.xlsx\")\n",
    "weeklyCsv      = last(\"sursaud-covid19-hebdomadaire-2020-04-08-19h00.csv\")\n",
    "\n",
    "hospAgeCsv     = last(\"donnees-hospitalieres-classe-age-covid19-2020-04-11-19h00.csv\")\n",
    "hospNouveauCsv = last(\"donnees-hospitalieres-nouveaux-covid19-2020-04-11-19h00.csv\")\n",
    "hospCsv        = last(\"donnees-hospitalieres-covid19-2020-04-11-19h00.csv\")\n",
    "hospEtablCsv   = last(\"donnees-hospitalieres-etablissements-covid19-2020-04-12-19h00.csv\")\n",
    "weeklyLabCsv   = last(\"donnees-tests-covid19-labo-hebdomadaire-2020-04-16-10h47.csv\")\n",
    "dailyLabCsv    = last(\"donnees-tests-covid19-labo-quotidien-2020-04-17-19h00.csv\")\n",
    "\n",
    "\n",
    "S1 = set (dataFileVMgr.listMostRecent())\n",
    "S2 =set((dailyDepCsv,dailyRegionCsv,dailyFranceCsv, dailyXlsx, weeklyCsv, \n",
    "         hospAgeCsv, hospNouveauCsv, hospCsv,  hospEtablCsv, weeklyLabCsv, dailyLabCsv  ))\n",
    "missing = S1. difference(S2)\n",
    "if len(missing) > 0:\n",
    "    print (f\"Missing comparing with most recent files in ../data:\")\n",
    "for f in missing:\n",
    "    print(f\"\\t{f}\")\n",
    "                \n",
    "metaHebdoCsv = \"../data/metadonnee-urgenceshos-sosmedecins-covid19-hebdo.csv\" \n",
    "metaQuotRegCsv = \"../data/metadonnee-urgenceshos-sosmedecin-covid19-quot-reg.csv\"\n",
    "metaQuotFraCsv = \"../data/metadonnee-urgenceshos-sosmedecin-covid19-quot-fra.csv\" \n",
    "metaQuotDepCsv = \"../data/metadonnee-urgenceshos-sosmedecins-covid19-quot-dep.csv\"\n",
    "metaQuotCsv = \"../data/metadonnee-urgenceshos-sosmedecin-covid19-quot.csv\"\n",
    "        \n",
    "metaHospservices = \"../data/metadonnees-services-hospitaliers-covid19.csv\"\n",
    "metaHospAge      = \"../data/metadonnees-donnees-hospitalieres-covid19-classes-age.csv\"\n",
    "metaHospIncid    = \"../data/metadonnees-hospit-incid.csv\"\n",
    "metaHospNouveau  = \"../data/metadonnees-donnees-hospitalieres-covid19-nouveaux.csv\"\n",
    "metaHosp         = \"../data/metadonnees-donnees-hospitalieres-covid19.csv\"\n",
    "metaHospEtabl    = \"../data/donnees-hospitalieres-etablissements-covid19-2020-04-11-19h00.csv\"\n",
    "\n",
    "metaAideEntr     = \"../data/metadonnees-aides-aux-entreprises.csv\"\n",
    "metaNivExcDC     = \"../data/metadonnees-niveaux-exces-mortalite-covid19.csv\"\n",
    "metaDepist       = \"../data/metadonnees-tests-depistage-covid19.csv\"\n",
    "\n",
    "metaSexeCsv = \"../data/metadonnees-sexe.csv\"\n",
    "metaRegionsCsv=\"../data/regions-france.csv\"\n",
    "metaTranchesAgeCsv=\"../data/code-tranches-dage.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fSolDep_csv = \"../data/fonds-solidarite-volet-1-departemental.csv\"\n",
    "fSolDep_xls= \"../data/fonds-solidarite-volet-1-departemental.xlsx\"\n",
    "fSolRegNaf_csv= \"../data/fonds-solidarite-volet-1-regional-naf.csv\"\n",
    "fSolRegNaf_xls= \"../data/fonds-solidarite-volet-1-regional-naf.xls\"\n",
    "indicExcesDCStand_csv= \"../data/indicateur-niveaux-exces-mortalite-standardise.csv\"\n",
    "indicExcesDCDep_csv= \"../data/niveaux-exces-mortalite-covid19-dep.csv\"\n",
    "indicExcesDCReg_csv= \"../data/niveaux-exces-mortalite-covid19-reg.csv\"\n",
    "incoherent_hebdo_xls= \"../data/sursaud-covid19-hebdomadaire-incoherence-01042020.xlsx\"\n",
    "incoherent_quot_xls= \"../data/sursaud-covid19-quotidien-incoherence-01042020.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ad  = lambda x: \"../data/\"+x\n",
    "S1 = set (map(ad, dataFileVMgr.listMostRecent(nonTS=True)))\n",
    "S2 =set((metaHebdoCsv, metaQuotRegCsv,  metaQuotFraCsv, metaQuotCsv, metaQuotDepCsv,\n",
    "         metaHospservices, metaHospAge, metaHospIncid, metaHosp,  metaHospEtabl, metaRegionsCsv, \n",
    "         metaTranchesAgeCsv, metaAideEntr,  metaNivExcDC,  metaDepist, metaHospNouveau,\n",
    "         fSolDep_csv, fSolDep_xls, fSolRegNaf_csv, fSolRegNaf_xls,\n",
    "         indicExcesDCStand_csv, indicExcesDCDep_csv, indicExcesDCReg_csv,  \n",
    "         incoherent_hebdo_xls, incoherent_quot_xls))\n",
    "missing = S1. difference(S2)\n",
    "if len(missing) > 0:\n",
    "    print (f\"Missing comparing with non timestamped files in ../data:\")\n",
    "for f in missing:\n",
    "    print(f\"\\t{f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load the stuff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ad  = lambda x: \"../data/\"+x\n",
    "\n",
    "data_fSolDep= read_xlsxPandas(fSolDep_xls)\n",
    "data_fSolRegNaf= read_xlsxPandas(fSolRegNaf_xls)\n",
    "data_indicExcesDCStand= read_csvPandas(indicExcesDCStand_csv,error_bad_lines=False,sep=\";\")\n",
    "data_indicExcesDCDep= read_csvPandas(indicExcesDCDep_csv,error_bad_lines=False,sep=\";\")\n",
    "data_indicExcesDCReg= read_csvPandas(indicExcesDCReg_csv,error_bad_lines=False,sep=\";\")\n",
    "data_incoherent_hebdo= read_xlsxPandas(incoherent_hebdo_xls)\n",
    "data_incoherent_quot= read_xlsxPandas(incoherent_quot_xls)\n",
    "\n",
    "meta_Hebdo       = read_csvPandas(metaHebdoCsv,     clearNaN=True, error_bad_lines=False,sep=\";\", header=2)\n",
    "meta_QuotReg     = read_csvPandas(metaQuotRegCsv, clearNaN=True, error_bad_lines=False,sep=\";\", header=1)\n",
    "meta_QuotFra     = read_csvPandas(metaQuotFraCsv, clearNaN=True, error_bad_lines=False,sep=\";\", header=1)\n",
    "meta_QuotDepCsv   = read_csvPandas(metaQuotDepCsv, clearNaN=True, error_bad_lines=False,sep=\";\", header=1)\n",
    "meta_Quot        = read_csvPandas(metaQuotCsv, clearNaN=True, error_bad_lines=False,sep=\";\", header=1)\n",
    "meta_HospServices = read_csvPandas(metaHospservices, clearNaN=True, error_bad_lines=False,sep=\";\")\n",
    "meta_HospAge      = read_csvPandas(metaHospAge, clearNaN=True, error_bad_lines=False,sep=\";\")\n",
    "meta_HospIncid    = read_csvPandas(metaHospIncid, clearNaN=True, error_bad_lines=False,sep=\";\")\n",
    "meta_Hosp         = read_csvPandas(metaHosp, clearNaN=True, error_bad_lines=False,sep=\";\")\n",
    "meta_HospNouveau  = read_csvPandas(metaHospNouveau, clearNaN=True, error_bad_lines=False,sep=\";\")\n",
    "\n",
    "meta_AideEntr    = read_csvPandas(metaAideEntr, clearNaN=True, error_bad_lines=False,sep=\",\")  \n",
    "meta_NivExcDC    = read_csvPandas(metaNivExcDC, clearNaN=True, error_bad_lines=False,sep=\";\")\n",
    "meta_Depist      = read_csvPandas(metaDepist, clearNaN=True, error_bad_lines=False,sep=\";\")\n",
    "\n",
    "meta_Sexe = read_csvPandas(metaSexeCsv, clearNaN=True, error_bad_lines=False,sep=\";\",header=0)\n",
    "meta_Regions = read_csvPandas(metaRegionsCsv, clearNaN=True, error_bad_lines=False,sep=\",\")\n",
    "meta_Ages    =  read_csvPandas(metaTranchesAgeCsv, clearNaN=True, error_bad_lines=False,sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure out data characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def showBasics(data,dataName):\n",
    "    print(f\"{dataName:24}\\thas shape {data.shape}\")\n",
    "\n",
    "dataListDescr = ((data_fSolDep, \"data_fSolDep\"),\n",
    "                 (data_fSolRegNaf, \"data_fSolRegNaf\"),\n",
    "                 (data_indicExcesDCStand, \"data_indicExcesDCStand\"),\n",
    "                 (data_indicExcesDCDep, \"data_indicExcesDCDep\"),\n",
    "                 (data_indicExcesDCReg, \"data_indicExcesDCReg\"),\n",
    "                 (data_incoherent_hebdo, \"data_incoherent_hebdo\"),\n",
    "                 (data_incoherent_quot, \"data_incoherent_quot\"),\n",
    "                 (meta_AideEntr,  \"meta_AideEntr\"), \n",
    "                 (meta_NivExcDC, \"meta_NivExcDC\"),\n",
    "                 (meta_Depist,     \"meta_Depist\"),    \n",
    "                  (meta_Hebdo,\"meta_Hebdo\"),\n",
    "                  (meta_QuotReg,\"meta_QuotReg\"),\n",
    "                  (meta_QuotFra,\"meta_QuotFra\"),\n",
    "                  (meta_Quot,\"meta_Quot\"),\n",
    "                  (meta_QuotDepCsv,\"meta_QuotDepCsv\"),\n",
    "                  (meta_HospServices,\"meta_HospServices\"),\n",
    "                  (meta_HospAge,\"meta_HospAge\"),\n",
    "                  (meta_HospIncid,\"meta_HospIncid\"),\n",
    "                  (meta_HospNouveau, \"meta_HospNouveau\"), \n",
    "                  (meta_Hosp,\"meta_Hosp\"),\n",
    "                  (meta_Sexe,\"meta_Sexe\"),\n",
    "                  (meta_Regions,'meta_Regions'),\n",
    "                  (meta_Ages,'meta_Ages'))\n",
    "    \n",
    "for (dat,name) in dataListDescr:\n",
    "    showBasics(dat,name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Help with meta data\n",
    "Of course I encountered some surprises, see `checkRepresentedRegions` issue with unknown codes which\n",
    "did occur in some files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def checkRepresentedRegions(df,col='reg',**kwOpts):\n",
    "    \"list regions represented in a dataframe, if kwd print=True, will print list of code->string\"\n",
    "    regs = set(df[col])\n",
    "    if \"print\" in kwOpts:\n",
    "        for r in regs:\n",
    "            extract = meta_Regions[ meta_Regions['code_region'] == r]\n",
    "            # print (f\"r={r}\\t{extract}\\t{extract.shape}\")\n",
    "            if extract.shape[0] == 0:\n",
    "                lib = f\"**Unknown:{r}**\"\n",
    "            else:\n",
    "                lib=extract.iloc[0]. at ['nom_region']\n",
    "            print(f\"Region: code={r}\\t->{lib}\")\n",
    "    return regs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for (dat,name) in dataListDescr:\n",
    "    if name[0:5]==\"meta_\": continue\n",
    "    print(f\"\\nDescription of data in '{name}'\\n\")\n",
    "    display(dat.describe().transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for (dat,name) in dataListDescr:\n",
    "    if name[0:5]!=\"meta_\": continue\n",
    "    print(f\"\\nMeta data in '{name}'\\n\")\n",
    "    display(dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get some demographics data from INSEE\n",
    "For the time being, these data are obtained / loaded from Insee web site using a manual process and are placed in a different directory, therefore a distinct FileManager is used, and loading this data is done here; for more details see the notebook `Pop-Data-FromGouv.ipy`\n",
    "\n",
    "Using the base version which does not try to update the \"../dataPop\" directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataFileVMgrInsee = manageDataFileVersions(\"../dataPop\") \n",
    "inseeDepXLS           =\"../dataPop/InseeDep.xls\"\n",
    "inseeDep            = read_xlsxPandas(inseeDepXLS, sheet_name=1, header=7)\n",
    "inseeReg            = read_xlsxPandas(inseeDepXLS, sheet_name=0, header=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can display our demographics data (summarized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(inseeDep.iloc[:,4:].sum())\n",
    "display(inseeReg.iloc[:,4:].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at the newer tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data_fSolDep.info())\n",
    "display(data_fSolDep.describe())\n",
    "display(data_fSolDep[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data_fSolRegNaf.info())\n",
    "display(data_fSolRegNaf.describe())\n",
    "display(data_fSolRegNaf[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_NivExcDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display( data_indicExcesDCStand.info())\n",
    "display( data_indicExcesDCStand.describe())\n",
    "display( data_indicExcesDCStand[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(data_indicExcesDCDep.info())\n",
    "display(data_indicExcesDCDep.describe())\n",
    "display(data_indicExcesDCDep[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data_indicExcesDCReg.info())\n",
    "display(data_indicExcesDCReg.describe())\n",
    "display(data_indicExcesDCReg[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display( data_incoherent_hebdo.info())\n",
    "display( data_incoherent_hebdo.describe())\n",
    "display( data_incoherent_hebdo[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display( data_incoherent_quot.info()) \n",
    "display( data_incoherent_quot.describe()) \n",
    "display( data_incoherent_quot[:10]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
